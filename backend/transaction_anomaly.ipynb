{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d42fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Moralis API key loaded successfully\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANALYZING TOKEN: 0x6982508145454ce325ddbe47a25d4ec3d2311933\n",
      "============================================================\n",
      "\n",
      "Fetching page 1...\n",
      "  Retrieved 100 transactions\n",
      "Fetching page 2...\n",
      "  Retrieved 100 transactions\n",
      "Fetching page 3...\n",
      "  Retrieved 100 transactions\n",
      "Fetching page 4...\n",
      "  Retrieved 100 transactions\n",
      "Fetching page 5...\n",
      "  Retrieved 100 transactions\n",
      "Total transactions fetched: 500\n",
      "\n",
      "--- Running Wash Trading Detection ---\n",
      "✓ Detected 2 suspicious wallets\n",
      "  (0 MEV bots filtered out)\n",
      "\n",
      "--- Running Price Manipulation Detection ---\n",
      "✓ Found 0 manipulation events\n",
      "  - Manipulation Events: 0\n",
      "  - Coordinated Trading: 0\n",
      "\n",
      "--- Running Pump & Dump Detection ---\n",
      "✓ Detected 0 potential schemes\n",
      "  - High Confidence: 0\n",
      "\n",
      "============================================================\n",
      "TRANSACTION ANOMALY DETECTION\n",
      "============================================================\n",
      "\n",
      "Token Address: 0x6982508145454ce325ddbe47a25d4ec3d2311933\n",
      "Chain: eth\n",
      "Analysis Date: 2025-10-17T19:02:18.710743\n",
      "Total Transactions Analyzed: 500\n",
      "\n",
      "OVERALL RISK SCORE: 16.0/100\n",
      "RISK LEVEL: LOW\n",
      "\n",
      "============================================================\n",
      "WASH TRADING DETECTION\n",
      "============================================================\n",
      "Suspicious Wallets: 2\n",
      "Total Suspicious Volume: $285,870.51\n",
      "Filtered out 0 likely MEV/arbitrage bots\n",
      "\n",
      "============================================================\n",
      "PRICE MANIPULATION DETECTION\n",
      "============================================================\n",
      "Total Events: 0\n",
      "Manipulation Events: 0\n",
      "Coordinated Trading Events: 0\n",
      "Highest Price Spike: 0.0%\n",
      "\n",
      "============================================================\n",
      "PUMP & DUMP DETECTION\n",
      "============================================================\n",
      "Detected Schemes: 0\n",
      "High Confidence Schemes: 0\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "✓ Results saved to: anomaly_report_20251017_190218.json\n",
      "\n",
      "=== TOP SUSPICIOUS WALLETS (Wash Trading) ===\n",
      "\n",
      "Wallet: 0x2a0085fedc4a7b5830d0503e0e39101474e98c6b\n",
      "  Round Trips: 3\n",
      "  Same Block Trades: 0\n",
      "  Total Volume: $1,293.59\n",
      "  Avg Trade Size: $323.40\n",
      "  Number of Trades: 4\n",
      "\n",
      "Wallet: 0x5b43453fce04b92e190f391a83136bfbecedefd1\n",
      "  Round Trips: 19\n",
      "  Same Block Trades: 18\n",
      "  Total Volume: $284,576.92\n",
      "  Avg Trade Size: $7,488.87\n",
      "  Number of Trades: 38\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "# ==================== API CLIENT ====================\n",
    "class MoralisSwapDataFetcher:\n",
    "    \"\"\"\n",
    "    Fetches ERC20 swap data from Moralis API with pagination and rate limiting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            api_key: Moralis API key\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://deep-index.moralis.io/api/v2.2\"\n",
    "        self.headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"X-API-Key\": api_key\n",
    "        }\n",
    "        self.rate_limit_delay = 0.2  # 200ms between requests\n",
    "    \n",
    "    def fetch_token_swaps(self, \n",
    "                         token_address: str,\n",
    "                         chain: str = \"eth\",\n",
    "                         limit: int = 100,\n",
    "                         max_pages: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Fetch swap transactions for a token with pagination.\n",
    "        \n",
    "        Args:\n",
    "            token_address: ERC20 token contract address\n",
    "            chain: Blockchain (eth, bsc, polygon, etc.)\n",
    "            limit: Results per page (max 100)\n",
    "            max_pages: Maximum pages to fetch\n",
    "            \n",
    "        Returns:\n",
    "            List of swap transactions\n",
    "        \"\"\"\n",
    "        all_transactions = []\n",
    "        cursor = None\n",
    "        page = 0\n",
    "        \n",
    "        url = f\"{self.base_url}/erc20/{token_address}/swaps\"\n",
    "        \n",
    "        while page < max_pages:\n",
    "            params = {\n",
    "                \"chain\": chain,\n",
    "                \"limit\": min(limit, 100),  # API max is 100\n",
    "                \"order\": \"DESC\"\n",
    "            }\n",
    "            \n",
    "            if cursor:\n",
    "                params[\"cursor\"] = cursor\n",
    "            \n",
    "            try:\n",
    "                print(f\"Fetching page {page + 1}...\")\n",
    "                response = requests.get(url, headers=self.headers, params=params)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                data = response.json()\n",
    "                \n",
    "                if \"result\" in data and data[\"result\"]:\n",
    "                    all_transactions.extend(data[\"result\"])\n",
    "                    print(f\"  Retrieved {len(data['result'])} transactions\")\n",
    "                    \n",
    "                    # Check for next page\n",
    "                    if \"cursor\" in data and data[\"cursor\"]:\n",
    "                        cursor = data[\"cursor\"]\n",
    "                        page += 1\n",
    "                        time.sleep(self.rate_limit_delay)  # Rate limiting\n",
    "                    else:\n",
    "                        break  # No more pages\n",
    "                else:\n",
    "                    break  # No results\n",
    "                    \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error fetching data: {e}\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Total transactions fetched: {len(all_transactions)}\")\n",
    "        return all_transactions\n",
    "    \n",
    "    def fetch_multiple_tokens(self, \n",
    "                             token_addresses: List[str],\n",
    "                             chain: str = \"eth\",\n",
    "                             limit: int = 100) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"\n",
    "        Fetch swaps for multiple tokens.\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping token addresses to their transactions\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for token in token_addresses:\n",
    "            print(f\"\\n=== Fetching data for token: {token} ===\")\n",
    "            results[token] = self.fetch_token_swaps(token, chain, limit)\n",
    "            time.sleep(self.rate_limit_delay)\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# ==================== ANOMALY DETECTORS ====================\n",
    "class WashTradingDetector:\n",
    "    \"\"\"Detects wash trading patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 time_window_minutes: int = 60,\n",
    "                 min_round_trips: int = 3,\n",
    "                 price_deviation_threshold: float = 0.02,\n",
    "                 min_same_block_trades: int = 5,  # Increased from 2\n",
    "                 min_volume_threshold: float = 1000.0):  # Min $1000 to flag\n",
    "        self.time_window = timedelta(minutes=time_window_minutes)\n",
    "        self.min_round_trips = min_round_trips\n",
    "        self.price_threshold = price_deviation_threshold\n",
    "        self.min_same_block = min_same_block_trades\n",
    "        self.min_volume = min_volume_threshold\n",
    "    \n",
    "    def detect(self, transactions: List[Dict]) -> Dict:\n",
    "        \"\"\"Detect wash trading patterns.\"\"\"\n",
    "        if not transactions:\n",
    "            return {'detected_count': 0, 'suspicious_wallets': {}, 'false_positive_note': ''}\n",
    "        \n",
    "        df = pd.DataFrame(transactions)\n",
    "        df['blockTimestamp'] = pd.to_datetime(df['blockTimestamp'])\n",
    "        df['baseQuotePrice'] = pd.to_numeric(df['baseQuotePrice'], errors='coerce')\n",
    "        df = df.sort_values('blockTimestamp')\n",
    "        \n",
    "        suspicious_wallets = {}\n",
    "        potential_mev_bots = []\n",
    "        \n",
    "        for wallet, group in df.groupby('walletAddress'):\n",
    "            patterns = self._analyze_wallet_pattern(group)\n",
    "            if patterns['is_suspicious']:\n",
    "                # Filter out likely MEV bots (very small trades, high frequency)\n",
    "                if patterns['is_likely_mev']:\n",
    "                    potential_mev_bots.append(wallet)\n",
    "                else:\n",
    "                    suspicious_wallets[wallet] = patterns\n",
    "        \n",
    "        return {\n",
    "            'detected_count': len(suspicious_wallets),\n",
    "            'suspicious_wallets': suspicious_wallets,\n",
    "            'total_suspicious_volume': sum(w['total_volume'] for w in suspicious_wallets.values()),\n",
    "            'mev_bots_filtered': len(potential_mev_bots),\n",
    "            'note': f\"Filtered out {len(potential_mev_bots)} likely MEV/arbitrage bots\"\n",
    "        }\n",
    "    \n",
    "    def _analyze_wallet_pattern(self, wallet_txs: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Analyze individual wallet trading patterns.\"\"\"\n",
    "        round_trips = []\n",
    "        buys = wallet_txs[wallet_txs['transactionType'] == 'buy'].copy()\n",
    "        sells = wallet_txs[wallet_txs['transactionType'] == 'sell'].copy()\n",
    "        \n",
    "        for _, buy in buys.iterrows():\n",
    "            matching_sells = sells[\n",
    "                (sells['blockTimestamp'] >= buy['blockTimestamp']) &\n",
    "                (sells['blockTimestamp'] <= buy['blockTimestamp'] + self.time_window)\n",
    "            ]\n",
    "            \n",
    "            for _, sell in matching_sells.iterrows():\n",
    "                if pd.notna(buy['baseQuotePrice']) and pd.notna(sell['baseQuotePrice']):\n",
    "                    price_diff = abs(buy['baseQuotePrice'] - sell['baseQuotePrice']) / buy['baseQuotePrice']\n",
    "                    \n",
    "                    if price_diff <= self.price_threshold:\n",
    "                        round_trips.append({\n",
    "                            'buy_time': buy['blockTimestamp'],\n",
    "                            'sell_time': sell['blockTimestamp'],\n",
    "                            'buy_value': buy['totalValueUsd'],\n",
    "                            'sell_value': sell['totalValueUsd'],\n",
    "                            'price_diff': price_diff,\n",
    "                            'time_diff_seconds': (sell['blockTimestamp'] - buy['blockTimestamp']).total_seconds()\n",
    "                        })\n",
    "        \n",
    "        same_block_trades = len(wallet_txs[wallet_txs.duplicated(subset=['blockNumber'], keep=False)])\n",
    "        total_volume = wallet_txs['totalValueUsd'].sum()\n",
    "        avg_trade_size = wallet_txs['totalValueUsd'].mean()\n",
    "        \n",
    "        # Check if likely MEV bot (small trades, same block activity)\n",
    "        is_likely_mev = (\n",
    "            same_block_trades >= 2 and \n",
    "            avg_trade_size < 100 and  # Small average trade size\n",
    "            total_volume < 500  # Low total volume\n",
    "        )\n",
    "        \n",
    "        # More stringent criteria for wash trading\n",
    "        is_suspicious = (\n",
    "            (len(round_trips) >= self.min_round_trips and total_volume >= self.min_volume) or\n",
    "            (same_block_trades >= self.min_same_block and total_volume >= self.min_volume)\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'is_suspicious': is_suspicious,\n",
    "            'is_likely_mev': is_likely_mev,\n",
    "            'round_trips': len(round_trips),\n",
    "            'same_block_trades': same_block_trades,\n",
    "            'total_volume': total_volume,\n",
    "            'avg_trade_size': avg_trade_size,\n",
    "            'num_trades': len(wallet_txs),\n",
    "            'avg_round_trip_time': np.mean([rt['time_diff_seconds'] for rt in round_trips]) if round_trips else 0,\n",
    "            'patterns': round_trips[:5]\n",
    "        }\n",
    "\n",
    "\n",
    "class PriceManipulationDetector:\n",
    "    \"\"\"Detects price manipulation patterns\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 price_spike_threshold: float = 0.15,  # Increased from 0.10\n",
    "                 volume_spike_multiplier: float = 10.0,  # Increased from 5.0\n",
    "                 min_manipulation_value: float = 5000.0):  # Min $5000 to flag\n",
    "        self.price_threshold = price_spike_threshold\n",
    "        self.volume_multiplier = volume_spike_multiplier\n",
    "        self.min_value = min_manipulation_value\n",
    "    \n",
    "    def detect(self, transactions: List[Dict]) -> Dict:\n",
    "        \"\"\"Detect price manipulation patterns.\"\"\"\n",
    "        if not transactions:\n",
    "            return {'manipulation_events': [], 'coordinated_trading': [], 'total_events': 0}\n",
    "        \n",
    "        df = pd.DataFrame(transactions)\n",
    "        df['blockTimestamp'] = pd.to_datetime(df['blockTimestamp'])\n",
    "        df['baseQuotePrice'] = pd.to_numeric(df['baseQuotePrice'], errors='coerce')\n",
    "        df = df.sort_values('blockNumber')\n",
    "        \n",
    "        manipulations = []\n",
    "        \n",
    "        df['price_change'] = df.groupby('pairAddress')['baseQuotePrice'].pct_change()\n",
    "        df['volume_ma'] = df.groupby('pairAddress')['totalValueUsd'].transform(\n",
    "            lambda x: x.rolling(window=20, min_periods=1).mean()  # Increased window\n",
    "        )\n",
    "        df['volume_spike'] = df['totalValueUsd'] / df['volume_ma']\n",
    "        \n",
    "        suspicious_idx = (\n",
    "            (abs(df['price_change']) > self.price_threshold) &\n",
    "            (df['volume_spike'] > self.volume_multiplier) &\n",
    "            (df['totalValueUsd'] > self.min_value)  # Added value filter\n",
    "        )\n",
    "        \n",
    "        for idx in df[suspicious_idx].index:\n",
    "            row = df.loc[idx]\n",
    "            manipulations.append({\n",
    "                'timestamp': row['blockTimestamp'],\n",
    "                'block': row['blockNumber'],\n",
    "                'price_change': row['price_change'],\n",
    "                'volume_spike': row['volume_spike'],\n",
    "                'wallet': row['walletAddress'],\n",
    "                'pair': row['pairLabel'],\n",
    "                'value_usd': row['totalValueUsd']\n",
    "            })\n",
    "        \n",
    "        coordinated = self._detect_coordinated_trading(df)\n",
    "        \n",
    "        return {\n",
    "            'manipulation_events': manipulations,\n",
    "            'coordinated_trading': coordinated,\n",
    "            'total_events': len(manipulations) + len(coordinated),\n",
    "            'highest_spike': max([abs(m['price_change']) for m in manipulations], default=0)\n",
    "        }\n",
    "    \n",
    "    def _detect_coordinated_trading(self, df: pd.DataFrame) -> List[Dict]:\n",
    "        \"\"\"Detect coordinated trading by multiple wallets - REFINED.\"\"\"\n",
    "        coordinated = []\n",
    "        \n",
    "        for block, group in df.groupby('blockNumber'):\n",
    "            unique_wallets = len(group['walletAddress'].unique())\n",
    "            total_value = group['totalValueUsd'].sum()\n",
    "            \n",
    "            # More stringent: need 5+ wallets AND $10k+ volume\n",
    "            if unique_wallets >= 5 and total_value > 10000:\n",
    "                coordinated.append({\n",
    "                    'block': int(block),\n",
    "                    'timestamp': group['blockTimestamp'].iloc[0],\n",
    "                    'num_wallets': unique_wallets,\n",
    "                    'total_value': total_value,\n",
    "                    'wallets': group['walletAddress'].tolist()[:10]  # Limit list size\n",
    "                })\n",
    "        \n",
    "        return coordinated\n",
    "\n",
    "\n",
    "class PumpAndDumpDetector:\n",
    "    \"\"\"Detects pump and dump schemes\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 pump_threshold: float = 0.50,  # Increased from 0.30\n",
    "                 dump_threshold: float = 0.30,  # Increased from 0.20\n",
    "                 min_wallets: int = 10,  # Increased from 5\n",
    "                 time_window_hours: int = 4):  # Added time constraint\n",
    "        self.pump_threshold = pump_threshold\n",
    "        self.dump_threshold = dump_threshold\n",
    "        self.min_wallets = min_wallets\n",
    "        self.time_window = timedelta(hours=time_window_hours)\n",
    "    \n",
    "    def detect(self, transactions: List[Dict]) -> Dict:\n",
    "        \"\"\"Detect pump and dump schemes.\"\"\"\n",
    "        if not transactions or len(transactions) < 50:\n",
    "            return {'detected_schemes': [], 'num_schemes': 0, 'high_confidence': []}\n",
    "        \n",
    "        df = pd.DataFrame(transactions)\n",
    "        df['blockTimestamp'] = pd.to_datetime(df['blockTimestamp'])\n",
    "        df['baseQuotePrice'] = pd.to_numeric(df['baseQuotePrice'], errors='coerce')\n",
    "        df = df.sort_values('blockTimestamp')\n",
    "        \n",
    "        schemes = []\n",
    "        \n",
    "        # Calculate rolling price changes over different windows\n",
    "        df['price_1h_change'] = df.groupby('pairAddress')['baseQuotePrice'].transform(\n",
    "            lambda x: x.pct_change(periods=min(len(x)-1, 10))\n",
    "        )\n",
    "        \n",
    "        # Find significant pumps\n",
    "        pumps = df[df['price_1h_change'] > self.pump_threshold].copy()\n",
    "        \n",
    "        for idx, pump_row in pumps.iterrows():\n",
    "            # Look for coordinated dump within time window\n",
    "            dump_window = df[\n",
    "                (df['blockTimestamp'] > pump_row['blockTimestamp']) &\n",
    "                (df['blockTimestamp'] <= pump_row['blockTimestamp'] + self.time_window)\n",
    "            ]\n",
    "            \n",
    "            sell_all = dump_window[dump_window['subCategory'] == 'sellAll']\n",
    "            unique_dumpers = len(sell_all['walletAddress'].unique())\n",
    "            dump_volume = sell_all['totalValueUsd'].sum()\n",
    "            \n",
    "            # Require significant dumping activity\n",
    "            if unique_dumpers >= self.min_wallets and dump_volume > 50000:\n",
    "                # Check for price collapse\n",
    "                if len(dump_window) > 0:\n",
    "                    price_after = dump_window['baseQuotePrice'].iloc[-1]\n",
    "                    price_drop = (pump_row['baseQuotePrice'] - price_after) / pump_row['baseQuotePrice']\n",
    "                    \n",
    "                    if price_drop >= self.dump_threshold:\n",
    "                        confidence = self._calculate_confidence(\n",
    "                            unique_dumpers, \n",
    "                            pump_row['price_1h_change'],\n",
    "                            price_drop,\n",
    "                            dump_volume\n",
    "                        )\n",
    "                        \n",
    "                        schemes.append({\n",
    "                            'pump_time': pump_row['blockTimestamp'],\n",
    "                            'pump_price_increase': pump_row['price_1h_change'],\n",
    "                            'dump_price_decrease': price_drop,\n",
    "                            'dump_wallets': unique_dumpers,\n",
    "                            'dump_volume': dump_volume,\n",
    "                            'confidence': confidence\n",
    "                        })\n",
    "        \n",
    "        return {\n",
    "            'detected_schemes': schemes,\n",
    "            'num_schemes': len(schemes),\n",
    "            'high_confidence': [s for s in schemes if s['confidence'] > 0.75]\n",
    "        }\n",
    "    \n",
    "    def _calculate_confidence(self, num_dumpers: int, pump_size: float, \n",
    "                             dump_size: float, volume: float) -> float:\n",
    "        \"\"\"Calculate confidence score with more factors.\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Dumpers count (max 0.25)\n",
    "        if num_dumpers >= 20:\n",
    "            score += 0.25\n",
    "        elif num_dumpers >= self.min_wallets:\n",
    "            score += 0.15\n",
    "        \n",
    "        # Pump magnitude (max 0.25)\n",
    "        if pump_size >= 1.0:  # 100%+\n",
    "            score += 0.25\n",
    "        elif pump_size >= self.pump_threshold:\n",
    "            score += 0.15\n",
    "        \n",
    "        # Dump magnitude (max 0.25)\n",
    "        if dump_size >= 0.5:  # 50%+\n",
    "            score += 0.25\n",
    "        elif dump_size >= self.dump_threshold:\n",
    "            score += 0.15\n",
    "        \n",
    "        # Volume (max 0.25)\n",
    "        if volume >= 100000:  # $100k+\n",
    "            score += 0.25\n",
    "        elif volume >= 50000:\n",
    "            score += 0.15\n",
    "        \n",
    "        return min(score, 1.0)\n",
    "\n",
    "\n",
    "# ==================== MAIN ANOMALY DETECTION SYSTEM ====================\n",
    "class CryptoAnomalyDetectionSystem:\n",
    "    \"\"\"\n",
    "    Complete system for detecting trading anomalies using Moralis API.\n",
    "    REFINED VERSION with better false positive handling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, moralis_api_key: str, sensitivity: str = \"medium\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            moralis_api_key: Moralis API key\n",
    "            sensitivity: Detection sensitivity (\"low\", \"medium\", \"high\")\n",
    "        \"\"\"\n",
    "        self.fetcher = MoralisSwapDataFetcher(moralis_api_key)\n",
    "        \n",
    "        # Adjust detector parameters based on sensitivity\n",
    "        if sensitivity == \"low\":\n",
    "            self.wash_detector = WashTradingDetector(\n",
    "                min_round_trips=5, min_same_block_trades=10, min_volume_threshold=5000\n",
    "            )\n",
    "            self.price_detector = PriceManipulationDetector(\n",
    "                price_spike_threshold=0.20, volume_spike_multiplier=15.0, min_manipulation_value=10000\n",
    "            )\n",
    "            self.pump_detector = PumpAndDumpDetector(\n",
    "                pump_threshold=0.70, dump_threshold=0.40, min_wallets=15\n",
    "            )\n",
    "        elif sensitivity == \"high\":\n",
    "            self.wash_detector = WashTradingDetector(\n",
    "                min_round_trips=2, min_same_block_trades=3, min_volume_threshold=500\n",
    "            )\n",
    "            self.price_detector = PriceManipulationDetector(\n",
    "                price_spike_threshold=0.10, volume_spike_multiplier=5.0, min_manipulation_value=1000\n",
    "            )\n",
    "            self.pump_detector = PumpAndDumpDetector(\n",
    "                pump_threshold=0.25, dump_threshold=0.15, min_wallets=5\n",
    "            )\n",
    "        else:  # medium (default)\n",
    "            self.wash_detector = WashTradingDetector()\n",
    "            self.price_detector = PriceManipulationDetector()\n",
    "            self.pump_detector = PumpAndDumpDetector()\n",
    "    \n",
    "    def analyze_token(self, \n",
    "                     token_address: str,\n",
    "                     chain: str = \"eth\",\n",
    "                     limit: int = 100,\n",
    "                     max_pages: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Complete anomaly analysis for a single token.\n",
    "        \n",
    "        Args:\n",
    "            token_address: ERC20 token contract address\n",
    "            chain: Blockchain network\n",
    "            limit: Transactions per page\n",
    "            max_pages: Maximum pages to fetch\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing all detection results\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANALYZING TOKEN: {token_address}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Fetch data\n",
    "        transactions = self.fetcher.fetch_token_swaps(\n",
    "            token_address, chain, limit, max_pages\n",
    "        )\n",
    "        \n",
    "        if not transactions:\n",
    "            print(\"No transactions found!\")\n",
    "            return None\n",
    "        \n",
    "        # Run all detectors\n",
    "        print(\"\\n--- Running Wash Trading Detection ---\")\n",
    "        wash_results = self.wash_detector.detect(transactions)\n",
    "        print(f\"✓ Detected {wash_results['detected_count']} suspicious wallets\")\n",
    "        if 'mev_bots_filtered' in wash_results:\n",
    "            print(f\"  ({wash_results['mev_bots_filtered']} MEV bots filtered out)\")\n",
    "        \n",
    "        print(\"\\n--- Running Price Manipulation Detection ---\")\n",
    "        price_results = self.price_detector.detect(transactions)\n",
    "        print(f\"✓ Found {price_results['total_events']} manipulation events\")\n",
    "        print(f\"  - Manipulation Events: {len(price_results['manipulation_events'])}\")\n",
    "        print(f\"  - Coordinated Trading: {len(price_results['coordinated_trading'])}\")\n",
    "        \n",
    "        print(\"\\n--- Running Pump & Dump Detection ---\")\n",
    "        pump_results = self.pump_detector.detect(transactions)\n",
    "        print(f\"✓ Detected {pump_results['num_schemes']} potential schemes\")\n",
    "        print(f\"  - High Confidence: {len(pump_results['high_confidence'])}\")\n",
    "        \n",
    "        # Compile results\n",
    "        results = {\n",
    "            'token_address': token_address,\n",
    "            'chain': chain,\n",
    "            'analysis_timestamp': datetime.now().isoformat(),\n",
    "            'total_transactions': len(transactions),\n",
    "            'wash_trading': wash_results,\n",
    "            'price_manipulation': price_results,\n",
    "            'pump_and_dump': pump_results,\n",
    "            'risk_score': self._calculate_risk_score(wash_results, price_results, pump_results),\n",
    "            'risk_level': self._get_risk_level(wash_results, price_results, pump_results)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_risk_score(self, wash: Dict, price: Dict, pump: Dict) -> float:\n",
    "        \"\"\"Calculate overall risk score (0-100) - REFINED.\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Wash trading component (max 35 points) - weighted by volume\n",
    "        if wash['detected_count'] > 0:\n",
    "            volume_factor = min(wash.get('total_suspicious_volume', 0) / 100000, 1.0)\n",
    "            score += min(wash['detected_count'] * 3, 25) + (volume_factor * 10)\n",
    "        \n",
    "        # Price manipulation component (max 35 points)\n",
    "        manipulation_count = len(price.get('manipulation_events', []))\n",
    "        coordinated_count = len(price.get('coordinated_trading', []))\n",
    "        if manipulation_count > 0:\n",
    "            score += min(manipulation_count * 10, 25)\n",
    "        if coordinated_count > 0:\n",
    "            score += min(coordinated_count * 2, 10)\n",
    "        \n",
    "        # Pump and dump component (max 30 points) - high confidence weighted more\n",
    "        high_conf = len(pump.get('high_confidence', []))\n",
    "        total_schemes = pump.get('num_schemes', 0)\n",
    "        if high_conf > 0:\n",
    "            score += min(high_conf * 15, 25)\n",
    "        elif total_schemes > 0:\n",
    "            score += min(total_schemes * 5, 10)\n",
    "        \n",
    "        return min(score, 100)\n",
    "    \n",
    "    def _get_risk_level(self, wash: Dict, price: Dict, pump: Dict) -> str:\n",
    "        \"\"\"Determine risk level category.\"\"\"\n",
    "        score = self._calculate_risk_score(wash, price, pump)\n",
    "        \n",
    "        if score >= 75:\n",
    "            return \"CRITICAL\"\n",
    "        elif score >= 50:\n",
    "            return \"HIGH\"\n",
    "        elif score >= 25:\n",
    "            return \"MEDIUM\"\n",
    "        elif score > 0:\n",
    "            return \"LOW\"\n",
    "        else:\n",
    "            return \"MINIMAL\"\n",
    "    \n",
    "    def generate_report(self, results: Dict) -> str:\n",
    "        \"\"\"Generate human-readable report.\"\"\"\n",
    "        if not results:\n",
    "            return \"No data to report\"\n",
    "        \n",
    "        risk_emoji = {\n",
    "            \"CRITICAL\": \"🚨\",\n",
    "            \"HIGH\": \"⚠️\",\n",
    "            \"MEDIUM\": \"⚡\",\n",
    "            \"LOW\": \"ℹ️\",\n",
    "            \"MINIMAL\": \"✅\"\n",
    "        }\n",
    "        \n",
    "        emoji = risk_emoji.get(results['risk_level'], \"❓\")\n",
    "        \n",
    "        report = f\"\"\"\n",
    "{'='*60}\n",
    "TRANSACTION ANOMALY DETECTION\n",
    "{'='*60}\n",
    "\n",
    "Token Address: {results['token_address']}\n",
    "Chain: {results['chain']}\n",
    "Analysis Date: {results['analysis_timestamp']}\n",
    "Total Transactions Analyzed: {results['total_transactions']}\n",
    "\n",
    "OVERALL RISK SCORE: {results['risk_score']:.1f}/100\n",
    "RISK LEVEL: {results['risk_level']}\n",
    "\n",
    "{'='*60}\n",
    "WASH TRADING DETECTION\n",
    "{'='*60}\n",
    "Suspicious Wallets: {results['wash_trading']['detected_count']}\n",
    "Total Suspicious Volume: ${results['wash_trading'].get('total_suspicious_volume', 0):,.2f}\n",
    "{results['wash_trading'].get('note', '')}\n",
    "\n",
    "{'='*60}\n",
    "PRICE MANIPULATION DETECTION\n",
    "{'='*60}\n",
    "Total Events: {results['price_manipulation']['total_events']}\n",
    "Manipulation Events: {len(results['price_manipulation']['manipulation_events'])}\n",
    "Coordinated Trading Events: {len(results['price_manipulation']['coordinated_trading'])}\n",
    "Highest Price Spike: {results['price_manipulation']['highest_spike']*100:.1f}%\n",
    "\n",
    "{'='*60}\n",
    "PUMP & DUMP DETECTION\n",
    "{'='*60}\n",
    "Detected Schemes: {results['pump_and_dump']['num_schemes']}\n",
    "High Confidence Schemes: {len(results['pump_and_dump']['high_confidence'])}\n",
    "\n",
    "{'='*60}\n",
    "\"\"\"\n",
    "        return report\n",
    "    \n",
    "    def save_results(self, results: Dict, filename: str = None):\n",
    "        \"\"\"Save results to JSON file.\"\"\"\n",
    "        if not filename:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"anomaly_report_{timestamp}.json\"\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"\\n✓ Results saved to: {filename}\")\n",
    "\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    \n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    moralis_key = os.getenv(\"MORALIS_KEY\")\n",
    "    \n",
    "    if not moralis_key:\n",
    "        raise ValueError(\"Please set the MORALIS_KEY environment variable\")\n",
    "    \n",
    "    print(\"✓ Moralis API key loaded successfully\\n\")\n",
    "    \n",
    "    # Initialize the system with MEDIUM sensitivity (balanced)\n",
    "    detector = CryptoAnomalyDetectionSystem(moralis_key, sensitivity=\"medium\")\n",
    "    \n",
    "    # Example: Analyze PEPE token\n",
    "    PEPE_ADDRESS = \"0x6982508145454ce325ddbe47a25d4ec3d2311933\"\n",
    "    \n",
    "    # Run analysis\n",
    "    results = detector.analyze_token(\n",
    "        token_address=PEPE_ADDRESS,\n",
    "        chain=\"eth\",\n",
    "        limit=100,\n",
    "        max_pages=5\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        # Print report\n",
    "        print(detector.generate_report(results))\n",
    "        \n",
    "        # Save results\n",
    "        detector.save_results(results)\n",
    "        \n",
    "        # Print top suspicious wallets with more detail\n",
    "        if results['wash_trading']['detected_count'] > 0:\n",
    "            print(\"\\n=== TOP SUSPICIOUS WALLETS (Wash Trading) ===\")\n",
    "            for wallet, data in list(results['wash_trading']['suspicious_wallets'].items())[:5]:\n",
    "                print(f\"\\nWallet: {wallet}\")\n",
    "                print(f\"  Round Trips: {data['round_trips']}\")\n",
    "                print(f\"  Same Block Trades: {data['same_block_trades']}\")\n",
    "                print(f\"  Total Volume: ${data['total_volume']:,.2f}\")\n",
    "                print(f\"  Avg Trade Size: ${data['avg_trade_size']:,.2f}\")\n",
    "                print(f\"  Number of Trades: {data['num_trades']}\")\n",
    "        \n",
    "        # Show high confidence pump & dumps\n",
    "        if len(results['pump_and_dump']['high_confidence']) > 0:\n",
    "            print(\"\\n=== HIGH CONFIDENCE PUMP & DUMP SCHEMES ===\")\n",
    "            for i, scheme in enumerate(results['pump_and_dump']['high_confidence'][:3], 1):\n",
    "                print(f\"\\nScheme #{i}:\")\n",
    "                print(f\"  Pump Time: {scheme['pump_time']}\")\n",
    "                print(f\"  Price Increase: {scheme['pump_price_increase']*100:.1f}%\")\n",
    "                print(f\"  Price Decrease: {scheme['dump_price_decrease']*100:.1f}%\")\n",
    "                print(f\"  Dumper Wallets: {scheme['dump_wallets']}\")\n",
    "                print(f\"  Dump Volume: ${scheme['dump_volume']:,.2f}\")\n",
    "                print(f\"  Confidence: {scheme['confidence']*100:.0f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
