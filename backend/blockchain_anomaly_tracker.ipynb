{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4736ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "import datetime\n",
    "from web3 import Web3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b031b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both API keys loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('ETHERSCAN_API_KEY')  \n",
    "coin_key = os.getenv('GECKO_API')\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set the ETHERSCAN_API_KEY environment variable\")\n",
    "\n",
    "if not coin_key:\n",
    "    raise ValueError(\"Please set the GECKO_API environment variable\")\n",
    "\n",
    "print(\"Both API keys loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5515073",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EtherscanAPI:\n",
    "    def __init__(self, api_key: str, coin_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.coin_key = coin_key\n",
    "        self.base_url = \"https://api.etherscan.io/v2/api\"\n",
    "\n",
    "    def get_transaction_details(self, tx_hash: str):\n",
    "        \"\"\"Fetch raw transaction details (from, to, value, gasPrice, hash, nonce, input)\"\"\"\n",
    "        url = (\n",
    "            f\"{self.base_url}\"\n",
    "            f\"?chainid=1\"\n",
    "            f\"&module=proxy\"\n",
    "            f\"&action=eth_getTransactionByHash\"\n",
    "            f\"&txhash={tx_hash}\"\n",
    "            f\"&apikey={self.api_key}\"\n",
    "        )\n",
    "        response = requests.get(url).json()\n",
    "        return response.get(\"result\", {})\n",
    "\n",
    "    def get_transaction_receipt(self, tx_hash: str):\n",
    "        \"\"\"Fetch transaction receipt (logs, status, gasUsed, contractAddress, blockNumber)\"\"\"\n",
    "        url = (\n",
    "            f\"{self.base_url}\"\n",
    "            f\"?chainid=1\"\n",
    "            f\"&module=proxy\"\n",
    "            f\"&action=eth_getTransactionReceipt\"\n",
    "            f\"&txhash={tx_hash}\"\n",
    "            f\"&apikey={self.api_key}\"\n",
    "        )\n",
    "        response = requests.get(url).json()\n",
    "        return response.get(\"result\", {})\n",
    "\n",
    "    def get_token_info(self, contract_address: str):\n",
    "        \"\"\"Fetch ERC20 token metadata using CoinGecko\"\"\"\n",
    "        try:\n",
    "            url = f\"https://api.coingecko.com/api/v3/coins/ethereum/contract/{contract_address}\"\n",
    "            response = requests.get(url).json()\n",
    "\n",
    "            if \"error\" in response:\n",
    "                return {}\n",
    "\n",
    "            return {\n",
    "                \"name\": response.get(\"name\"),\n",
    "                \"symbol\": response.get(\"symbol\"),\n",
    "                \"decimals\": response.get(\"detail_platforms\", {})\n",
    "                               .get(\"ethereum\", {})\n",
    "                               .get(\"decimal_place\", 18)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching token info from CoinGecko: {e}\")\n",
    "            return {\"name\": \"Unknown Token\", \"symbol\": \"UNKNOWN\", \"decimals\": 18}\n",
    "\n",
    "    def get_single_transaction_analysis(self, tx_hash: str):\n",
    "        \"\"\"Analyze a single transaction: ETH transfer, ERC20 transfer, approval, or contract interaction\"\"\"\n",
    "        try:\n",
    "            tx_details = self.get_transaction_details(tx_hash)\n",
    "            tx_receipt = self.get_transaction_receipt(tx_hash)\n",
    "\n",
    "            if not tx_details or not tx_receipt:\n",
    "                return None\n",
    "\n",
    "            # Get block timestamp\n",
    "            block_number = tx_receipt.get(\"blockNumber\", \"0x0\")\n",
    "            block_url = (\n",
    "                f\"{self.base_url}\"\n",
    "                f\"?chainid=1\"\n",
    "                f\"&module=proxy\"\n",
    "                f\"&action=eth_getBlockByNumber\"\n",
    "                f\"&tag={block_number}\"\n",
    "                f\"&boolean=true\"\n",
    "                f\"&apikey={self.api_key}\"\n",
    "            )\n",
    "            block_response = requests.get(block_url).json()\n",
    "            block_data = block_response.get(\"result\", {})\n",
    "            timestamp = str(int(block_data[\"timestamp\"], 16)) if block_data.get(\"timestamp\") else \"0\"\n",
    "\n",
    "            # Extract logs\n",
    "            logs = tx_receipt.get(\"logs\", [])\n",
    "\n",
    "            # Topics\n",
    "            transfer_topic = \"0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef\"\n",
    "            approval_topic = \"0x8c5be1e5ebec7d5bd14f71427d1e84f3dd0314c0f7b2291e5b200ac8c7c3b925\"\n",
    "\n",
    "            # Default ETH value\n",
    "            eth_value = int(tx_details.get(\"value\", \"0x0\"), 16) / 1e18\n",
    "\n",
    "            tx_data = {\n",
    "                \"hash\": tx_hash,\n",
    "                \"from\": tx_details.get(\"from\", \"\"),\n",
    "                \"to\": tx_details.get(\"to\", \"\"),\n",
    "                \"blockNumber\": block_number,\n",
    "                \"timeStamp\": timestamp,\n",
    "                \"gasUsed\": tx_receipt.get(\"gasUsed\", \"0\"),\n",
    "                \"gasPrice\": tx_details.get(\"gasPrice\", \"0\"),\n",
    "                \"status\": tx_receipt.get(\"status\", \"0x0\"),\n",
    "                # Defaults to prevent KeyError\n",
    "                \"value\": \"0\",\n",
    "                \"tokenName\": None,\n",
    "                \"tokenSymbol\": None,\n",
    "                \"tokenDecimal\": None,\n",
    "                \"tokenAddress\": None,\n",
    "                \"tx_type\": \"unknown\"\n",
    "            }\n",
    "\n",
    "            # ERC20 Transfer\n",
    "            for log in logs:\n",
    "                topics = log.get(\"topics\", [])\n",
    "                if topics and topics[0] == transfer_topic and len(topics) >= 3:\n",
    "                    from_address = \"0x\" + topics[1][-40:]\n",
    "                    to_address = \"0x\" + topics[2][-40:]\n",
    "                    token_contract = log.get(\"address\", \"\")\n",
    "\n",
    "                    token_info = self.get_token_info(token_contract)\n",
    "                    data = log.get(\"data\", \"0x0\")\n",
    "\n",
    "                    try:\n",
    "                        amount_wei = int(data, 16)\n",
    "                        decimals = int(token_info.get(\"decimals\", 18))\n",
    "                        amount = amount_wei / (10**decimals)\n",
    "                    except:\n",
    "                        amount, decimals = 0, 18\n",
    "\n",
    "                    tx_data.update({\n",
    "                        \"from\": from_address,\n",
    "                        \"to\": to_address,\n",
    "                        \"value\": str(amount),\n",
    "                        \"tokenName\": token_info.get(\"name\"),\n",
    "                        \"tokenSymbol\": token_info.get(\"symbol\"),\n",
    "                        \"tokenDecimal\": str(decimals),\n",
    "                        \"tokenAddress\": token_contract,\n",
    "                        \"tx_type\": \"erc20_transfer\"\n",
    "                    })\n",
    "                    return tx_data  # first match only\n",
    "\n",
    "            # ERC20 Approval\n",
    "            for log in logs:\n",
    "                topics = log.get(\"topics\", [])\n",
    "                if topics and topics[0] == approval_topic and len(topics) >= 3:\n",
    "                    owner = \"0x\" + topics[1][-40:]\n",
    "                    spender = \"0x\" + topics[2][-40:]\n",
    "                    token_contract = log.get(\"address\", \"\")\n",
    "\n",
    "                    token_info = self.get_token_info(token_contract)\n",
    "                    data = log.get(\"data\", \"0x0\")\n",
    "\n",
    "                    try:\n",
    "                        amount_wei = int(data, 16)\n",
    "                        decimals = int(token_info.get(\"decimals\", 18))\n",
    "                        amount = amount_wei / (10**decimals)\n",
    "                    except:\n",
    "                        amount, decimals = 0, 18\n",
    "\n",
    "                    tx_data.update({\n",
    "                        \"owner\": owner,\n",
    "                        \"spender\": spender,\n",
    "                        \"value\": str(amount),\n",
    "                        \"tokenName\": token_info.get(\"name\"),\n",
    "                        \"tokenSymbol\": token_info.get(\"symbol\"),\n",
    "                        \"tokenDecimal\": str(decimals),\n",
    "                        \"tokenAddress\": token_contract,\n",
    "                        \"tx_type\": \"erc20_approval\"\n",
    "                    })\n",
    "                    return tx_data\n",
    "\n",
    "            # ETH Transfer\n",
    "            if eth_value > 0: # Ensures ETH was transferred (not just a contract call)\n",
    "                tx_data.update({\n",
    "                    \"value\": str(eth_value),\n",
    "                    \"tokenName\": \"Ethereum\",\n",
    "                    \"tokenSymbol\": \"ETH\",\n",
    "                    \"tokenDecimal\": \"18\",\n",
    "                    \"tokenAddress\": \"0x0000000000000000000000000000000000000000\",\n",
    "                    \"tx_type\": \"eth_transfer\"\n",
    "                })\n",
    "                return tx_data\n",
    "\n",
    "            # Contract Interaction\n",
    "            if tx_details.get(\"input\") and tx_details[\"input\"] != \"0x\":\n",
    "                method_id = tx_details[\"input\"][:10]\n",
    "                tx_data.update({\n",
    "                    \"methodId\": method_id,\n",
    "                    \"input\": tx_details[\"input\"],\n",
    "                    \"tx_type\": \"contract_interaction\"\n",
    "                })\n",
    "                return tx_data\n",
    "\n",
    "            # Default (failed/other)\n",
    "            tx_data.update({\"tx_type\": \"other\"})\n",
    "            return tx_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing transaction {tx_hash}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ebbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web3 import Web3\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class InputDecoder:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.abi_cache = {}\n",
    "        self.w3 = Web3()\n",
    "\n",
    "    def get_abi(self, contract_address: str):\n",
    "        \"\"\"Fetch ABI from Etherscan (with caching).\"\"\"\n",
    "        if contract_address in self.abi_cache:\n",
    "            return self.abi_cache[contract_address]\n",
    "\n",
    "        url = (\n",
    "            f\"https://api.etherscan.io/api\"\n",
    "            f\"?module=contract\"\n",
    "            f\"&action=getabi\"\n",
    "            f\"&address={contract_address}\"\n",
    "            f\"&apikey={self.api_key}\"\n",
    "        )\n",
    "        resp = requests.get(url).json()\n",
    "        if resp[\"status\"] == \"1\":\n",
    "            abi = json.loads(resp[\"result\"])\n",
    "            self.abi_cache[contract_address] = abi\n",
    "            return abi\n",
    "        return None\n",
    "\n",
    "    def decode(self, contract_address: str, input_data: str):\n",
    "        \"\"\"Decode transaction input using verified ABI.\"\"\"\n",
    "        abi = self.get_abi(contract_address)\n",
    "        if not abi:\n",
    "            return {\"error\": \"Contract ABI not verified on Etherscan\"}\n",
    "\n",
    "        try:\n",
    "            checksum_address = self.w3.to_checksum_address(contract_address)\n",
    "            contract = self.w3.eth.contract(address=checksum_address, abi=abi)\n",
    "            func_obj, func_params = contract.decode_function_input(input_data)\n",
    "            return {\n",
    "                \"method\": func_obj.fn_name,\n",
    "                \"params\": func_params\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50725f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockchainAnomalyTracker:\n",
    "    def __init__(self, api_key: str,  coin_key: str):\n",
    "        # API handles transactions + token info\n",
    "        self.api = EtherscanAPI(api_key, coin_key) \n",
    "        # Decoder handles method signatures\n",
    "        self.decoder = InputDecoder(api_key) # only etherscan key usually needed\n",
    "  \n",
    "    # Preprocessing\n",
    "    def preprocess_data(self, data: List[Dict], is_single_tx: bool = False) -> pd.DataFrame:\n",
    "        if not data:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Timestamp\n",
    "        if \"timeStamp\" in df.columns:\n",
    "            df[\"timeStamp\"] = pd.to_datetime(\n",
    "                df[\"timeStamp\"].astype(int), unit=\"s\", errors=\"coerce\"\n",
    "            )\n",
    "        else:\n",
    "            df[\"timeStamp\"] = pd.NaT\n",
    "\n",
    "        # Value (safe handling)\n",
    "        if \"value\" not in df.columns:\n",
    "            df[\"value\"] = 0.0\n",
    "        else:\n",
    "            def safe_value(v):\n",
    "                try:\n",
    "                    return float(v)\n",
    "                except:\n",
    "                    return 0.0\n",
    "            df[\"value\"] = df[\"value\"].apply(safe_value)\n",
    "\n",
    "        # Gas fee (safe conversion)\n",
    "        def safe_gas_conversion(row):\n",
    "            try:\n",
    "                gas_used = row.get(\"gasUsed\", \"0\")\n",
    "                gas_price = row.get(\"gasPrice\", \"0\")\n",
    "\n",
    "                gas_used = int(gas_used, 16) if isinstance(gas_used, str) and gas_used.startswith(\"0x\") else int(gas_used)\n",
    "                gas_price = int(gas_price, 16) if isinstance(gas_price, str) and gas_price.startswith(\"0x\") else int(gas_price)\n",
    "\n",
    "                return gas_used * gas_price / 1e18\n",
    "            except:\n",
    "                return 0\n",
    "        df[\"gasFee_ETH\"] = df.apply(safe_gas_conversion, axis=1)\n",
    "\n",
    "        # Decode method names from input\n",
    "        if \"input\" in df.columns:\n",
    "            df[\"decoded_method\"] = df[\"input\"].apply(self.decoder.decode_method)\n",
    "        else:\n",
    "            df[\"decoded_method\"] = \"none\"\n",
    "\n",
    "        # Date + hour fields\n",
    "        df[\"date\"] = df[\"timeStamp\"].dt.date\n",
    "        df[\"hour\"] = df[\"timeStamp\"].dt.floor(\"h\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Classifiers\n",
    "    def classify_gas_fees(self, gas_fee: float) -> str:\n",
    "        if gas_fee < 0.000005:\n",
    "            return \"extremely_low\"\n",
    "        elif gas_fee <= 0.859339:\n",
    "            return \"normal\"\n",
    "        else:\n",
    "            return \"high\"\n",
    "\n",
    "    def classify_transfer_amounts(self, amount: float) -> str:\n",
    "        if amount < 1000:\n",
    "            return \"retail_sender\"\n",
    "        elif amount < 10000:\n",
    "            return \"small_active\"\n",
    "        elif amount < 100000:\n",
    "            return \"mid_tier\"\n",
    "        elif amount < 1000000:\n",
    "            return \"high_value\"\n",
    "        else:\n",
    "            return \"institutional\"\n",
    "\n",
    "    def classify_transaction_frequency(self, tx_count: int) -> str:\n",
    "        if tx_count <= 5:\n",
    "            return \"dormant_trader\"\n",
    "        elif tx_count <= 20:\n",
    "            return \"active_trader\"\n",
    "        elif tx_count <= 100:\n",
    "            return \"high_frequency_bot\"\n",
    "        else:\n",
    "            return \"extreme_anomaly\"\n",
    "\n",
    "    def classify_recipient_volume(self, hourly_amount: float) -> str:\n",
    "        if hourly_amount < 1000:\n",
    "            return \"retail_recipient\"\n",
    "        elif hourly_amount < 10000:\n",
    "            return \"active_recipient\"\n",
    "        elif hourly_amount < 100000:\n",
    "            return \"dolphin\"\n",
    "        elif hourly_amount < 1000000:\n",
    "            return \"shark\"\n",
    "        else:\n",
    "            return \"whale\"\n",
    "\n",
    "    # Anomaly Detector\n",
    "    def detect_gas_anomalies(self, df: pd.DataFrame) -> Dict:\n",
    "        df[\"gas_category\"] = df[\"gasFee_ETH\"].apply(self.classify_gas_fees)\n",
    "        return {\n",
    "            \"summary\": df[\"gas_category\"].value_counts().to_dict(),\n",
    "            \"extremely_low_transactions\": df[df[\"gas_category\"] == \"extremely_low\"].shape[0],\n",
    "            \"high_gas_transactions\": df[df[\"gas_category\"] == \"high\"].shape[0],\n",
    "            \"gas_stats\": df[\"gasFee_ETH\"].agg([\"max\", \"min\", \"mean\"]).to_dict(),\n",
    "        }\n",
    "\n",
    "    def detect_large_transfers(self, df: pd.DataFrame) -> Dict:\n",
    "        df[\"transfer_category\"] = df[\"value\"].apply(self.classify_transfer_amounts)\n",
    "        daily_stats = df.groupby(\"date\")[\"value\"].agg(\n",
    "            largest_transfer=\"max\",\n",
    "            smallest_transfer=\"min\",\n",
    "            average_transfer=\"mean\",\n",
    "        ).reset_index()\n",
    "        return {\n",
    "            \"transfer_categories\": df[\"transfer_category\"].value_counts().to_dict(),\n",
    "            \"daily_stats\": daily_stats.to_dict(\"records\"),\n",
    "            \"institutional_transfers\": df[df[\"transfer_category\"] == \"institutional\"].shape[0],\n",
    "            \"high_value_transfers\": df[df[\"transfer_category\"] == \"high_value\"].shape[0],\n",
    "        }\n",
    "\n",
    "    def detect_sender_anomalies(self, df: pd.DataFrame) -> Dict:\n",
    "        sender_counts = df.groupby([\"from\", \"hour\"])[\"hash\"].count().rename(\"tx_count\").reset_index()\n",
    "        sender_counts[\"frequency_category\"] = sender_counts[\"tx_count\"].apply(self.classify_transaction_frequency)\n",
    "\n",
    "        def detect_sender_anomalies_group(group):\n",
    "            mean = group[\"tx_count\"].mean()\n",
    "            std = group[\"tx_count\"].std()\n",
    "            if std == 0:\n",
    "                return pd.DataFrame()\n",
    "            return group[group[\"tx_count\"] > mean + 2 * std]\n",
    "\n",
    "        sender_anomalies = sender_counts.groupby(\"from\", group_keys=False).apply(detect_sender_anomalies_group)\n",
    "        return {\n",
    "            \"frequency_categories\": sender_counts[\"frequency_category\"].value_counts().to_dict(),\n",
    "            \"anomalous_senders\": len(sender_anomalies[\"from\"].unique()) if not sender_anomalies.empty else 0,\n",
    "            \"high_frequency_actors\": sender_counts[\n",
    "                sender_counts[\"frequency_category\"].isin([\"high_frequency_bot\", \"extreme_anomaly\"])\n",
    "            ].shape[0],\n",
    "            \"statistical_anomalies\": sender_anomalies.to_dict(\"records\") if not sender_anomalies.empty else [],\n",
    "        }\n",
    "\n",
    "    def detect_recipient_anomalies(self, df: pd.DataFrame) -> Dict:\n",
    "        recipient_hourly = df.groupby([\"to\", df[\"timeStamp\"].dt.floor(\"h\")])[\"value\"].sum().reset_index()\n",
    "        recipient_hourly.columns = [\"to\", \"hour\", \"hourly_amount\"]\n",
    "        recipient_hourly[\"volume_category\"] = recipient_hourly[\"hourly_amount\"].apply(self.classify_recipient_volume)\n",
    "\n",
    "        def detect_recipient_anomalies_group(group):\n",
    "            median = group[\"hourly_amount\"].median()\n",
    "            std = group[\"hourly_amount\"].std()\n",
    "            if std == 0:\n",
    "                return pd.DataFrame()\n",
    "            return group[group[\"hourly_amount\"] > median + 2 * std]\n",
    "\n",
    "        recipient_anomalies = recipient_hourly.groupby(\"to\", group_keys=False).apply(detect_recipient_anomalies_group)\n",
    "        return {\n",
    "            \"volume_categories\": recipient_hourly[\"volume_category\"].value_counts().to_dict(),\n",
    "            \"whale_recipients\": recipient_hourly[recipient_hourly[\"volume_category\"] == \"whale\"].shape[0],\n",
    "            \"shark_recipients\": recipient_hourly[recipient_hourly[\"volume_category\"] == \"shark\"].shape[0],\n",
    "            \"statistical_anomalies\": recipient_anomalies.to_dict(\"records\") if not recipient_anomalies.empty else [],\n",
    "        }\n",
    "\n",
    "    def detect_approval_anomalies(self, df: pd.DataFrame) -> Dict:\n",
    "        approvals = df[df[\"decoded_method\"].str.contains(\"approve\", case=False, na=False)]\n",
    "        grouped = approvals.groupby(\"from\").size()\n",
    "        suspicious = grouped[grouped > 5]\n",
    "        return {\n",
    "            \"total_approvals\": len(approvals),\n",
    "            \"suspicious_approvers\": suspicious.to_dict(),\n",
    "        }\n",
    "\n",
    "    def detect_swap_anomalies(self, df: pd.DataFrame) -> Dict:\n",
    "        swaps = df[df[\"decoded_method\"].str.contains(\"swap\", case=False, na=False)]\n",
    "        grouped = swaps.groupby(\"from\").size()\n",
    "        whales = grouped[grouped > 10]\n",
    "        return {\n",
    "            \"total_swaps\": len(swaps),\n",
    "            \"heavy_swap_traders\": whales.to_dict(),\n",
    "        }\n",
    "\n",
    "    def detect_flashloan_anomalies(self, df: pd.DataFrame) -> Dict:\n",
    "        flashloans = df[df[\"decoded_method\"].str.contains(\"flashloan|executeOperation\", case=False, na=False)]\n",
    "        return {\n",
    "            \"total_flashloans\": len(flashloans),\n",
    "            \"flashloan_txs\": flashloans[[\"hash\", \"from\", \"to\"]].to_dict(\"records\"),\n",
    "        }\n",
    "    \n",
    "    def detect_tx_type(self, tx_data: Dict, decoded_method: str) -> str:\n",
    "        \"\"\"Detect transaction type based on value and decoded method.\"\"\"\n",
    "        if tx_data.get(\"input\") == \"0x\" and float(tx_data.get(\"value\", 0)) > 0:\n",
    "            return \"eth_transfer\"\n",
    "        if decoded_method:\n",
    "            method = decoded_method.lower()\n",
    "            if \"transfer\" in method:\n",
    "                return \"erc20_transfer\"\n",
    "            elif \"approve\" in method:\n",
    "                return \"erc20_approval\"\n",
    "            elif \"swap\" in method:\n",
    "                return \"swap\"\n",
    "            elif \"flashloan\" in method or \"executeoperation\" in method:\n",
    "                return \"flashloan\"\n",
    "        return \"contract_interaction\"\n",
    "    \n",
    "    def analyze_single_transaction(self, tx_hash: str) -> Dict:\n",
    "        \"\"\"Unified, simplified anomaly analysis for a single transaction hash.\"\"\"\n",
    "        try:\n",
    "            # Step 1: Get raw tx analysis\n",
    "            tx_data = self.api.get_single_transaction_analysis(tx_hash)\n",
    "            if not tx_data:\n",
    "                return {\"error\": f\"No transaction found for hash {tx_hash}\"}\n",
    "\n",
    "            # Step 2: Decode method\n",
    "            decoded_method = None\n",
    "            if tx_data.get(\"input\") and tx_data.get(\"to\"):\n",
    "                method_id = tx_data[\"input\"][:10]\n",
    "                decoded_method = self.decoder.decode(tx_data[\"to\"], method_id)\n",
    "                tx_data[\"decoded_method\"] = decoded_method\n",
    "\n",
    "            # Step 3: Preprocess into DataFrame\n",
    "            df = self.preprocess_data([tx_data], is_single_tx=True)\n",
    "\n",
    "            # Step 4: Run detectors (extract risk flags instead of raw dumps)\n",
    "            gas_summary = self.detect_gas_anomalies(df)\n",
    "            gas_usage = (\n",
    "                list(gas_summary[\"summary\"].keys())[0]\n",
    "                if gas_summary[\"summary\"]\n",
    "                else \"unknown\"\n",
    "            )\n",
    "\n",
    "            transfer_summary = self.detect_large_transfers(df)\n",
    "            transfer_category = (\n",
    "                list(transfer_summary[\"transfer_categories\"].keys())[0]\n",
    "                if transfer_summary[\"transfer_categories\"]\n",
    "                else \"unknown\"\n",
    "            )\n",
    "\n",
    "            approval_summary = self.detect_approval_anomalies(df)\n",
    "            swap_summary = self.detect_swap_anomalies(df)\n",
    "            flashloan_summary = self.detect_flashloan_anomalies(df)\n",
    "\n",
    "            # Step 5: Detect tx type\n",
    "            tx_type = self.detect_tx_type(tx_data, decoded_method)\n",
    "\n",
    "            # Step 6: Build structured response\n",
    "            report = {\n",
    "                \"analysis_type\": \"transaction_analysis\",\n",
    "                \"tx_hash\": tx_hash,\n",
    "                \"transaction_details\": {\n",
    "                    \"from\": tx_data.get(\"from\"),\n",
    "                    \"to\": tx_data.get(\"to\"),\n",
    "                    \"token\": {\n",
    "                        \"name\": tx_data.get(\"tokenName\", \"ETH\" if tx_type == \"eth_transfer\" else None),\n",
    "                        \"symbol\": tx_data.get(\"tokenSymbol\", \"ETH\" if tx_type == \"eth_transfer\" else None),\n",
    "                        \"decimals\": tx_data.get(\"tokenDecimal\", 18 if tx_type == \"eth_transfer\" else None),\n",
    "                    },\n",
    "                    \"value\": f\"{tx_data.get('value')} {tx_data.get('tokenSymbol', 'ETH')}\",\n",
    "                    \"method\": decoded_method,\n",
    "                    \"tx_type\": tx_type,\n",
    "                    \"gas_fee_eth\": f\"{df.iloc[0]['gasFee_ETH']:.8f} ETH\"\n",
    "                },\n",
    "                \"risk_flags\": {\n",
    "                    \"gas_usage\": gas_usage,\n",
    "                    \"transfer_category\": transfer_category,\n",
    "                    \"approval_anomaly\": approval_summary[\"total_approvals\"] > 0,\n",
    "                    \"swap_activity\": swap_summary[\"total_swaps\"] > 0,\n",
    "                    \"flashloan_activity\": flashloan_summary[\"total_flashloans\"] > 0,\n",
    "                },\n",
    "                \"verdict\": self.build_verdict(\n",
    "                    tx_type,\n",
    "                    tx_data.get(\"value\"),\n",
    "                    tx_data.get(\"tokenSymbol\", \"ETH\"),\n",
    "                    gas_usage,\n",
    "                    transfer_category,\n",
    "                    approval_summary,\n",
    "                    swap_summary,\n",
    "                    flashloan_summary,\n",
    "                )\n",
    "            }\n",
    "\n",
    "            # Fix datetime serialization\n",
    "            def convert(obj):\n",
    "                if isinstance(obj, (datetime.date, datetime.datetime)):\n",
    "                    return obj.isoformat()\n",
    "                raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "            return json.loads(json.dumps(report, default=convert))\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Single tx analysis failed: {str(e)}\"}\n",
    "        \n",
    "    def build_verdict(\n",
    "        self,\n",
    "        tx_type,\n",
    "        value,\n",
    "        symbol,\n",
    "        gas_usage,\n",
    "        transfer_category,\n",
    "        approval_summary,\n",
    "        swap_summary,\n",
    "        flashloan_summary,\n",
    "    ) -> str:\n",
    "        \"\"\"Generate a human-readable verdict string.\"\"\"\n",
    "        if tx_type == \"erc20_transfer\":\n",
    "            return f\"This is a standard ERC20 transfer of {value} {symbol} with {gas_usage} gas usage. No anomalies detected.\"\n",
    "        if tx_type == \"eth_transfer\":\n",
    "            return f\"This is a standard ETH transfer of {value} ETH with {gas_usage} gas usage.\"\n",
    "        if tx_type == \"erc20_approval\":\n",
    "            return \"This is an ERC20 approval transaction.\"\n",
    "        if tx_type == \"swap\":\n",
    "            return \"This is a swap transaction.\"\n",
    "        if tx_type == \"flashloan\":\n",
    "            return \"This is a flashloan transaction.\"\n",
    "        return \"This is a generic contract interaction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2874b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"analysis_type\": \"transaction_analysis\",\n",
      "  \"tx_hash\": \"0x4df7980aaf09db72a7cd8888667f721cd878465391294f744f8f304a9b907701\",\n",
      "  \"transaction_details\": {\n",
      "    \"from\": \"0x1d42064fc4beb5f8aaf85f4617ae8b3b5b8bd801\",\n",
      "    \"to\": \"0xf5213a6a2f0890321712520b8048d9886c1a9900\",\n",
      "    \"token\": {\n",
      "      \"name\": \"WETH\",\n",
      "      \"symbol\": \"weth\",\n",
      "      \"decimals\": \"18\"\n",
      "    },\n",
      "    \"value\": \"0.5226778980474429 weth\",\n",
      "    \"method\": null,\n",
      "    \"tx_type\": \"contract_interaction\",\n",
      "    \"gas_fee_eth\": \"0.00002408 ETH\"\n",
      "  },\n",
      "  \"risk_flags\": {\n",
      "    \"gas_usage\": \"normal\",\n",
      "    \"transfer_category\": \"retail_sender\",\n",
      "    \"approval_anomaly\": false,\n",
      "    \"swap_activity\": false,\n",
      "    \"flashloan_activity\": false\n",
      "  },\n",
      "  \"verdict\": \"This is a generic contract interaction.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tracker\n",
    "tracker = BlockchainAnomalyTracker(api_key=api_key, coin_key=coin_key)\n",
    "\n",
    "tx_hash = \"0x4df7980aaf09db72a7cd8888667f721cd878465391294f744f8f304a9b907701\"\n",
    "\n",
    "# Run analysis\n",
    "result = tracker.analyze_single_transaction(tx_hash)\n",
    "\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ddf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def analyze_single_transaction(self, tx_hash: str) -> Dict:\n",
    "        \"\"\"Unified anomaly analysis for a single transaction hash.\"\"\"\n",
    "        try:\n",
    "            # Step 1: Get raw tx analysis\n",
    "            tx_data = self.api.get_single_transaction_analysis(tx_hash)\n",
    "            if not tx_data:\n",
    "                return {\"error\": f\"No transaction found for hash {tx_hash}\"}\n",
    "\n",
    "            # Step 2: Decode method\n",
    "            decoded_method = None\n",
    "            if tx_data.get(\"input\") and tx_data.get(\"to\"):\n",
    "                method_id = tx_data[\"input\"][:10]\n",
    "                decoded_method = self.decoder.decode(tx_data[\"to\"], method_id)\n",
    "                tx_data[\"decoded_method\"] = decoded_method\n",
    "\n",
    "            # Step 3: Preprocess into DataFrame\n",
    "            df = self.preprocess_data([tx_data], is_single_tx=True)\n",
    "\n",
    "            # Step 4: Build full report\n",
    "            report = {\n",
    "                \"analysis_type\": \"transaction_analysis\",\n",
    "                \"tx_hash\": tx_hash,\n",
    "                \"summary\": {\n",
    "                    \"from\": tx_data.get(\"from\"),\n",
    "                    \"to\": tx_data.get(\"to\"),\n",
    "                    \"value\": tx_data.get(\"value\"),\n",
    "                    \"decoded_method\": decoded_method,\n",
    "                    \"tx_type\": tx_data.get(\"tx_type\"),\n",
    "                },\n",
    "                \"gas_anomalies\": self.detect_gas_anomalies(df),\n",
    "                \"transfer_analysis\": self.detect_large_transfers(df),\n",
    "                \"approval_anomalies\": self.detect_approval_anomalies(df),\n",
    "                \"swap_anomalies\": self.detect_swap_anomalies(df),\n",
    "                \"flashloan_anomalies\": self.detect_flashloan_anomalies(df),\n",
    "            }\n",
    "\n",
    "            # Step 5: Ensure JSON-safe return\n",
    "            def convert(obj):\n",
    "                if isinstance(obj, (datetime.date, datetime.datetime)):\n",
    "                    return obj.isoformat()\n",
    "                raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "            return json.loads(json.dumps(report, default=convert))\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Single tx analysis failed: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3922d3b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (260003696.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef analyze_transactions(self, address_or_hash: str, is_transaction_hash: bool = None) -> Dict:\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " # Main Analyzer\n",
    "    def analyze_transactions(self, address_or_hash: str, is_transaction_hash: bool = None) -> Dict:\n",
    "        try:\n",
    "            if is_transaction_hash is None:\n",
    "                is_transaction_hash = len(address_or_hash) == 66 and address_or_hash.startswith(\"0x\")\n",
    "\n",
    "            if is_transaction_hash:\n",
    "                # you can plug in analyze_single_transaction here if you want\n",
    "                return {\"error\": \"Single tx analysis not implemented in this snippet\"}\n",
    "            else:\n",
    "                data = self.api.get_token_transactions(address_or_hash)\n",
    "                if not data:\n",
    "                    return {\"error\": \"No transaction data found\"}\n",
    "                df = self.preprocess_data(data, is_single_tx=False)\n",
    "                if df.empty:\n",
    "                    return {\"error\": \"No valid transaction data to analyze\"}\n",
    "\n",
    "                return {\n",
    "                    \"analysis_type\": \"address_analysis\",\n",
    "                    \"address\": address_or_hash,\n",
    "                    \"summary\": {\n",
    "                        \"total_transactions\": len(df),\n",
    "                        \"unique_methods\": df[\"decoded_method\"].nunique(),\n",
    "                        \"most_common_method\": df[\"decoded_method\"].mode().iloc[0] if not df[\"decoded_method\"].empty else None,\n",
    "                    },\n",
    "                    \"gas_anomalies\": self.detect_gas_anomalies(df),\n",
    "                    \"transfer_analysis\": self.detect_large_transfers(df),\n",
    "                    \"sender_anomalies\": self.detect_sender_anomalies(df),\n",
    "                    \"recipient_anomalies\": self.detect_recipient_anomalies(df),\n",
    "                    \"approval_anomalies\": self.detect_approval_anomalies(df),\n",
    "                    \"swap_anomalies\": self.detect_swap_anomalies(df),\n",
    "                    \"flashloan_anomalies\": self.detect_flashloan_anomalies(df),\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Analysis failed: {str(e)}\"}\n",
    "        \n",
    "    # Single Transaction Analysis\n",
    "    def analyze_single_transaction(self, tx_hash: str) -> Dict:\n",
    "        \"\"\"Analyze a single transaction hash for anomalies\"\"\"\n",
    "        try:\n",
    "            data = self.api.get_transaction_by_hash(tx_hash)\n",
    "            if not data:\n",
    "                return {\"error\": f\"No transaction found for hash {tx_hash}\"}\n",
    "\n",
    "            df = self.preprocess_data([data], is_single_tx=True)\n",
    "            if df.empty:\n",
    "                return {\"error\": \"Failed to preprocess transaction\"}\n",
    "\n",
    "            tx = df.iloc[0]\n",
    "\n",
    "            # Check ETH transfer\n",
    "            if tx[\"value\"] > 0 and tx[\"to\"] is not None:\n",
    "                return {\n",
    "                    \"tx_type\": \"eth_transfer\",\n",
    "                    \"hash\": tx_hash,\n",
    "                    \"from\": tx[\"from\"],\n",
    "                    \"to\": tx[\"to\"],\n",
    "                    \"value\": tx[\"value\"],\n",
    "                    \"gasFee_ETH\": tx[\"gasFee_ETH\"],\n",
    "                }\n",
    "\n",
    "            # Decode method\n",
    "            method = tx[\"decoded_method\"]\n",
    "\n",
    "            # ERC20 Approvals\n",
    "            if \"approve\" in method.lower():\n",
    "                return {\n",
    "                    \"tx_type\": \"erc20_approval\",\n",
    "                    \"hash\": tx_hash,\n",
    "                    \"from\": tx[\"from\"],\n",
    "                    \"to\": tx.get(\"to\", None),\n",
    "                    \"method\": method,\n",
    "                    \"gasFee_ETH\": tx[\"gasFee_ETH\"],\n",
    "                }\n",
    "\n",
    "            # Swaps\n",
    "            if \"swap\" in method.lower():\n",
    "                return {\n",
    "                    \"tx_type\": \"swap\",\n",
    "                    \"hash\": tx_hash,\n",
    "                    \"from\": tx[\"from\"],\n",
    "                    \"to\": tx.get(\"to\", None),\n",
    "                    \"method\": method,\n",
    "                    \"gasFee_ETH\": tx[\"gasFee_ETH\"],\n",
    "                }\n",
    "\n",
    "            # Flashloans\n",
    "            if \"flashloan\" in method.lower() or \"executeOperation\" in method.lower():\n",
    "                return {\n",
    "                    \"tx_type\": \"flashloan\",\n",
    "                    \"hash\": tx_hash,\n",
    "                    \"from\": tx[\"from\"],\n",
    "                    \"to\": tx.get(\"to\", None),\n",
    "                    \"method\": method,\n",
    "                    \"gasFee_ETH\": tx[\"gasFee_ETH\"],\n",
    "                }\n",
    "\n",
    "            # Generic fallback\n",
    "            return {\n",
    "                \"tx_type\": \"contract_call\",\n",
    "                \"hash\": tx_hash,\n",
    "                \"from\": tx[\"from\"],\n",
    "                \"to\": tx.get(\"to\", None),\n",
    "                \"method\": method,\n",
    "                \"gasFee_ETH\": tx[\"gasFee_ETH\"],\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Single tx analysis failed: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48534d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class EtherscanAPI:\n",
    "    def __init__(self, api_key: str, coin_key: str = \"eth\"):\n",
    "        self.api_key = api_key\n",
    "        self.coin_key = coin_key\n",
    "        self.base_url = \"https://api.etherscan.io/api\"\n",
    "\n",
    "    def get_token_transactions(self, address: str, startblock: int = 0, endblock: int = 99999999) -> list:\n",
    "        url = (\n",
    "            f\"{self.base_url}\"\n",
    "            f\"?module=account\"\n",
    "            f\"&action=tokentx\"\n",
    "            f\"&address={address}\"\n",
    "            f\"&startblock={startblock}\"\n",
    "            f\"&endblock={endblock}\"\n",
    "            f\"&sort=asc\"\n",
    "            f\"&apikey={self.api_key}\"\n",
    "        )\n",
    "        response = requests.get(url).json()\n",
    "        return response.get(\"result\", [])\n",
    "\n",
    "    def get_transaction_by_hash(self, tx_hash: str) -> dict:\n",
    "        \"\"\"Fetch a single transaction by hash\"\"\"\n",
    "        url = (\n",
    "            f\"{self.base_url}\"\n",
    "            f\"?module=proxy\"\n",
    "            f\"&action=eth_getTransactionByHash\"\n",
    "            f\"&txhash={tx_hash}\"\n",
    "            f\"&apikey={self.api_key}\"\n",
    "        )\n",
    "        response = requests.get(url).json()\n",
    "        return response.get(\"result\", {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f527f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": \"Single tx analysis failed: 'InputDecoder' object has no attribute 'decode_method'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example test for a single transaction\n",
    "tracker = BlockchainAnomalyTracker(api_key=api_key, coin_key=coin_key)\n",
    "\n",
    "tx_hash = \"0xc87c2991683b432a481d386b65a5a1eab6b732607afb2fd690c57d4ba0efc02c\"  \n",
    "\n",
    "result = tracker.analyze_single_transaction(tx_hash)\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e9f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": \"Analysis failed: 'InputDecoder' object has no attribute 'decode_method'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example test for an address\n",
    "tracker = BlockchainAnomalyTracker(api_key=api_key, coin_key=coin_key)\n",
    "\n",
    "address = \"0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48\"  # USDC contract address\n",
    "result = tracker.analyze_transactions(address)\n",
    "\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b283933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
